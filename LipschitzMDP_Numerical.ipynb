{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fcf56487",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from dataclasses import dataclass\n",
    "from typing import Callable, Dict, Optional, Tuple\n",
    "import matplotlib.pyplot as plt\n",
    "from math import comb\n",
    "\n",
    "# --------------------------------------------------------------------\n",
    "# Simplex discretization for base-stock policies\n",
    "# --------------------------------------------------------------------\n",
    "def simplex_grid(n: int, m: int) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Construct a uniform grid on the (n-1)-simplex:\n",
    "        { z in R^n : z_i >= 0, sum_i z_i = 1 }\n",
    "    with coordinates in {0, 1/m, 2/m, ..., 1}.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    n : int\n",
    "        Number of locations (dimension of the simplex).\n",
    "    m : int\n",
    "        Resolution parameter; larger m gives finer grid and more arms.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    grid : np.ndarray, shape (K, n)\n",
    "        Each row is a base-stock vector b in Δ_{n-1}.\n",
    "    \"\"\"\n",
    "    if n < 2:\n",
    "        raise ValueError(\"n must be at least 2.\")\n",
    "    if m < 1:\n",
    "        raise ValueError(\"m must be at least 1.\")\n",
    "\n",
    "    grid = []\n",
    "\n",
    "    def _rec(prefix, remaining, dim):\n",
    "        # Recursive construction of integer compositions of 'm' into 'n' parts.\n",
    "        if dim == n - 1:\n",
    "            # Last coordinate determined by what's left.\n",
    "            prefix.append(remaining)\n",
    "            grid.append(np.array(prefix, dtype=float) / m)\n",
    "            prefix.pop()\n",
    "            return\n",
    "\n",
    "        for k in range(remaining + 1):\n",
    "            prefix.append(k)\n",
    "            _rec(prefix, remaining - k, dim + 1)\n",
    "            prefix.pop()\n",
    "\n",
    "    _rec([], m, 0)\n",
    "    return np.vstack(grid)\n",
    "\n",
    "\n",
    "# --------------------------------------------------------------------\n",
    "# Network inventory environment\n",
    "# --------------------------------------------------------------------\n",
    "class NetworkInventoryEnv:\n",
    "    \"\"\"\n",
    "    Closed network inventory MDP with n locations.\n",
    "\n",
    "    - State x_t is a probability vector in the simplex Δ_{n-1}.\n",
    "    - Action y_t is a base-stock vector in the simplex Δ_{n-1}.\n",
    "    - Dynamics: x_{t+1} = (y_t - d_t)^+ + P_t^T min(y_t, d_t),\n",
    "      followed by normalization to stay on the simplex.\n",
    "    - Repositioning cost: M(y_t - x_t) with uniform per-unit cost c_ij ≡ c.\n",
    "    - Lost-sales cost: l * sum_i (d_{t,i} - y_{t,i})^+.\n",
    "    - Modified cost: \\tilde{C}_t = M(y_t - x_t) - l * sum_i min(d_{t,i}, y_{t,i}).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        n: int,\n",
    "        demand_sampler: Callable[[np.random.Generator, int], np.ndarray],\n",
    "        routing_sampler: Callable[[np.random.Generator, int], np.ndarray],\n",
    "        cost_reposition: float = 1.0,\n",
    "        cost_lost: float = 5.0,\n",
    "        x0: Optional[np.ndarray] = None,\n",
    "        rng: Optional[np.random.Generator] = None,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        n : int\n",
    "            Number of locations.\n",
    "        demand_sampler : callable\n",
    "            Function (rng, n) -> demand vector d in R_+^n.\n",
    "        routing_sampler : callable\n",
    "            Function (rng, n) -> row-stochastic routing matrix P in R^{n x n}.\n",
    "        cost_reposition : float\n",
    "            Uniform per-unit repositioning cost c.\n",
    "        cost_lost : float\n",
    "            Uniform lost-sales cost per unit l.\n",
    "        x0 : np.ndarray, optional\n",
    "            Initial state; if None, use uniform distribution.\n",
    "        rng : np.random.Generator, optional\n",
    "            Random number generator.\n",
    "        \"\"\"\n",
    "        self.n = n\n",
    "        self.demand_sampler = demand_sampler\n",
    "        self.routing_sampler = routing_sampler\n",
    "        self.cost_reposition = float(cost_reposition)\n",
    "        self.cost_lost = float(cost_lost)\n",
    "        self.rng = rng or np.random.default_rng()\n",
    "\n",
    "        if x0 is None:\n",
    "            self.x = np.ones(n, dtype=float) / n\n",
    "        else:\n",
    "            x0 = np.asarray(x0, dtype=float)\n",
    "            if x0.shape != (n,):\n",
    "                raise ValueError(\"x0 must have shape (n,)\")\n",
    "            if x0.sum() <= 0:\n",
    "                raise ValueError(\"x0 must have positive total inventory.\")\n",
    "            self.x = x0 / x0.sum()\n",
    "\n",
    "    @property\n",
    "    def state(self) -> np.ndarray:\n",
    "        \"\"\"Current inventory distribution x_t.\"\"\"\n",
    "        return self.x\n",
    "\n",
    "    def reset(self, x0: Optional[np.ndarray] = None) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Reset environment to initial state.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x0 : np.ndarray, optional\n",
    "            Initial state; if None, uses uniform.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        x : np.ndarray\n",
    "            Reset state.\n",
    "        \"\"\"\n",
    "        if x0 is None:\n",
    "            self.x = np.ones(self.n, dtype=float) / self.n\n",
    "        else:\n",
    "            x0 = np.asarray(x0, dtype=float)\n",
    "            if x0.shape != (self.n,):\n",
    "                raise ValueError(\"x0 must have shape (n,)\")\n",
    "            if x0.sum() <= 0:\n",
    "                raise ValueError(\"x0 must have positive total inventory.\")\n",
    "            self.x = x0 / x0.sum()\n",
    "        return self.x\n",
    "\n",
    "    def reposition_cost(self, x_from: np.ndarray, y_to: np.ndarray) -> float:\n",
    "        \"\"\"\n",
    "        Minimal repositioning cost M(y - x) under uniform transportation cost.\n",
    "\n",
    "        We specialize to c_ij = c (constant) for i != j and c_ii = 0.\n",
    "        In this case the optimal cost is\n",
    "\n",
    "            M(y - x) = c * 0.5 * ||y - x||_1,\n",
    "\n",
    "        because the total mass moved equals half the L1 distance.\n",
    "        \"\"\"\n",
    "        x_from = np.asarray(x_from, dtype=float)\n",
    "        y_to = np.asarray(y_to, dtype=float)\n",
    "        if x_from.shape != (self.n,) or y_to.shape != (self.n,):\n",
    "            raise ValueError(\"x_from and y_to must have shape (n,)\")\n",
    "\n",
    "        return 0.5 * self.cost_reposition * np.abs(y_to - x_from).sum()\n",
    "\n",
    "    def step(\n",
    "        self, y: np.ndarray\n",
    "    ) -> Tuple[np.ndarray, float, float, float, Dict[str, np.ndarray]]:\n",
    "        \"\"\"\n",
    "        Apply target inventory level y, realize demand and routing, and update state.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        y : np.ndarray\n",
    "            Target inventory distribution in the simplex Δ_{n-1}.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        x_next : np.ndarray\n",
    "            Next state x_{t+1}.\n",
    "        total_cost : float\n",
    "            Single-period cost C_t = M(y_t - x_t) + lost-sales cost.\n",
    "        modified_cost : float\n",
    "            Observable modified cost \\tilde{C}_t.\n",
    "        repo_cost : float\n",
    "            Repositioning cost M(y_t - x_t).\n",
    "        info : dict\n",
    "            Dictionary with keys 'demand', 'routing', 'sold', 'lost'.\n",
    "        \"\"\"\n",
    "        y = np.asarray(y, dtype=float)\n",
    "        if y.shape != (self.n,):\n",
    "            raise ValueError(\"y must have shape (n,)\")\n",
    "        if np.any(y < -1e-8):\n",
    "            raise ValueError(\"y must be nonnegative.\")\n",
    "        total_y = y.sum()\n",
    "        if not np.isclose(total_y, 1.0):\n",
    "            # Normalize to stay on the simplex if user passes an unnormalized vector.\n",
    "            y = y / total_y\n",
    "\n",
    "        x_prev = self.x.copy()\n",
    "        # Repositioning cost from current state to target base-stock vector.\n",
    "        repo_cost = self.reposition_cost(x_prev, y)\n",
    "\n",
    "        # Realize demand and routing.\n",
    "        d = np.asarray(self.demand_sampler(self.rng, self.n), dtype=float)\n",
    "        if d.shape != (self.n,):\n",
    "            raise ValueError(\"demand_sampler must return shape (n,)\")\n",
    "        if np.any(d < 0):\n",
    "            raise ValueError(\"Demand must be nonnegative.\")\n",
    "\n",
    "        P = np.asarray(self.routing_sampler(self.rng, self.n), dtype=float)\n",
    "        if P.shape != (self.n, self.n):\n",
    "            raise ValueError(\"routing_sampler must return shape (n, n)\")\n",
    "\n",
    "        # Ensure each row of P is a probability distribution.\n",
    "        row_sums = P.sum(axis=1, keepdims=True)\n",
    "        P = np.divide(\n",
    "            P,\n",
    "            row_sums,\n",
    "            out=np.full_like(P, 1.0 / self.n),\n",
    "            where=row_sums > 0,\n",
    "        )\n",
    "\n",
    "        # Censored sales and lost demand.\n",
    "        sold = np.minimum(y, d)           # fulfilled demand min(y_i, d_i)\n",
    "        lost = np.maximum(d - y, 0.0)     # lost demand (d_i - y_i)^+\n",
    "\n",
    "        # Inventory dynamics: (y - d)^+ + P^T * sold.\n",
    "        leftover = y - sold\n",
    "        x_next = leftover + P.T @ sold\n",
    "\n",
    "        # Numerical tidy-up: renormalize to stay on the simplex.\n",
    "        total = x_next.sum()\n",
    "        if total > 0:\n",
    "            x_next /= total\n",
    "\n",
    "        # Lost-sales cost (uniform loss cost per unit).\n",
    "        lost_sales_cost = self.cost_lost * lost.sum()\n",
    "\n",
    "        total_cost = repo_cost + lost_sales_cost\n",
    "\n",
    "        # Modified cost: M(y - x_t) - l * sum_i min(y_i, d_i)\n",
    "        modified_cost = repo_cost - self.cost_lost * sold.sum()\n",
    "\n",
    "        # Commit state transition.\n",
    "        self.x = x_next\n",
    "\n",
    "        info = {\n",
    "            \"demand\": d,\n",
    "            \"routing\": P,\n",
    "            \"sold\": sold,\n",
    "            \"lost\": lost,\n",
    "        }\n",
    "\n",
    "        return x_next, total_cost, modified_cost, repo_cost, info\n",
    "\n",
    "\n",
    "# --------------------------------------------------------------------\n",
    "# LipBR configuration and algorithm\n",
    "# --------------------------------------------------------------------\n",
    "@dataclass\n",
    "class LipBRConfig:\n",
    "    horizon: int\n",
    "    grid_m: int = 4      # resolution of simplex discretization\n",
    "    H: float = 5.0       # UCB exploration parameter\n",
    "\n",
    "\n",
    "class LipBR:\n",
    "    \"\"\"\n",
    "    Lipschitz Bandits-based Repositioning (LipBR) algorithm.\n",
    "\n",
    "    - Discretizes the base-stock policy space by a grid on Δ_{n-1}.\n",
    "    - Treats each grid point as an arm.\n",
    "    - Uses an epoch-based UCB strategy on pseudo modified costs with\n",
    "      memory points to approximate the \"consecutive play\" requirement\n",
    "      in the concentration inequalities.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, env: NetworkInventoryEnv, config: LipBRConfig):\n",
    "        self.env = env\n",
    "        self.cfg = config\n",
    "        self.n = env.n\n",
    "\n",
    "        # Discretize base-stock policies (arms).\n",
    "        self.B = simplex_grid(self.n, self.cfg.grid_m)  # shape (K, n)\n",
    "        self.K = self.B.shape[0]\n",
    "\n",
    "        # Epoch length per arm (N_k in the paper), start with 1.\n",
    "        self.epoch_lengths = np.ones(self.K, dtype=int)\n",
    "\n",
    "        # Number of times each arm has been played (τ_k).\n",
    "        self.tau = np.zeros(self.K, dtype=int)\n",
    "\n",
    "        # Sum of pseudo modified costs per arm (for empirical means).\n",
    "        self.sum_pseudo_cost = np.zeros(self.K, dtype=float)\n",
    "\n",
    "        # UCB values per arm (initialize to +∞ to force exploration).\n",
    "        self.UCB = np.full(self.K, np.inf, dtype=float)\n",
    "\n",
    "        # Memory points m_k: last state at end of an epoch where arm k was used.\n",
    "        self.memory_state = np.tile(self.env.state, (self.K, 1))\n",
    "\n",
    "    def run(self, verbose: bool = False) -> Dict[str, np.ndarray]:\n",
    "        \"\"\"\n",
    "        Run LipBR for the given time horizon.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        verbose : bool\n",
    "            If True, prints basic epoch information.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        history : dict\n",
    "            Dictionary containing per-period statistics and arm-level summaries.\n",
    "        \"\"\"\n",
    "        T = self.cfg.horizon\n",
    "        H = self.cfg.H\n",
    "\n",
    "        # Per-period logs.\n",
    "        chosen_arms = np.empty(T, dtype=int)\n",
    "        total_costs = np.empty(T, dtype=float)\n",
    "        modified_costs = np.empty(T, dtype=float)\n",
    "        pseudo_costs = np.empty(T, dtype=float)\n",
    "        avg_modified_cost = np.empty(T, dtype=float)\n",
    "\n",
    "        t = 0\n",
    "        epoch = 0\n",
    "        last_arm: Optional[int] = None\n",
    "        cum_modified_cost = 0.0\n",
    "\n",
    "        while t < T:\n",
    "            epoch += 1\n",
    "\n",
    "            # Select arm with highest UCB (ties broken by smallest index).\n",
    "            k = int(np.argmax(self.UCB))\n",
    "            base_stock = self.B[k]\n",
    "            N_k = self.epoch_lengths[k]\n",
    "\n",
    "            if verbose:\n",
    "                print(\n",
    "                    f\"Epoch {epoch}: arm {k}, length {N_k}, \"\n",
    "                    f\"tau={self.tau[k]}, UCB={self.UCB[k]:.3f}\"\n",
    "                )\n",
    "\n",
    "            # Play arm k for N_k consecutive periods (or until horizon ends).\n",
    "            for _ in range(N_k):\n",
    "                if t >= T:\n",
    "                    break\n",
    "\n",
    "                x_prev = self.env.state.copy()\n",
    "\n",
    "                (x_next,\n",
    "                 total_cost,\n",
    "                 mod_cost,\n",
    "                 repo_cost_prev,\n",
    "                 info) = self.env.step(base_stock)\n",
    "\n",
    "                # Pseudo modified cost adjustment (equation analogue (21)):\n",
    "                #   \\tilde{C}'_t = \\tilde{C}_t + M(b_k - m_k) - M(b_k - x_t)\n",
    "                # when we switch into arm k.\n",
    "                if last_arm is None or k == last_arm:\n",
    "                    pseudo_cost = mod_cost\n",
    "                else:\n",
    "                    repo_cost_mem = self.env.reposition_cost(\n",
    "                        self.memory_state[k], base_stock\n",
    "                    )\n",
    "                    pseudo_cost = mod_cost + repo_cost_mem - repo_cost_prev\n",
    "\n",
    "                # Update statistics for arm k.\n",
    "                self.sum_pseudo_cost[k] += pseudo_cost\n",
    "                self.tau[k] += 1\n",
    "\n",
    "                # Logging per-period data.\n",
    "                chosen_arms[t] = k\n",
    "                total_costs[t] = total_cost\n",
    "                modified_costs[t] = mod_cost\n",
    "                pseudo_costs[t] = pseudo_cost\n",
    "\n",
    "                cum_modified_cost += mod_cost\n",
    "                avg_modified_cost[t] = cum_modified_cost / (t + 1)\n",
    "\n",
    "                t += 1\n",
    "                last_arm = k\n",
    "\n",
    "            # End of epoch for arm k: update memory point and its UCB.\n",
    "            self.memory_state[k] = self.env.state.copy()\n",
    "\n",
    "            # Empirical mean pseudo cost for arm k.\n",
    "            mean_pseudo_cost = self.sum_pseudo_cost[k] / max(self.tau[k], 1)\n",
    "            # Treat \"reward\" as negative cost and apply UCB.\n",
    "            self.UCB[k] = -mean_pseudo_cost + H * np.sqrt(\n",
    "                np.log(T) / max(self.tau[k], 1)\n",
    "            )\n",
    "\n",
    "            # Double the epoch length for this arm.\n",
    "            self.epoch_lengths[k] *= 2\n",
    "\n",
    "        # Summarize per-arm performance.\n",
    "        mean_pseudo_per_arm = np.full(self.K, np.nan, dtype=float)\n",
    "        for k in range(self.K):\n",
    "            if self.tau[k] > 0:\n",
    "                mean_pseudo_per_arm[k] = self.sum_pseudo_cost[k] / self.tau[k]\n",
    "\n",
    "        # Approximate pseudo-regret using in-sample best arm in discretized set.\n",
    "        valid = np.isfinite(mean_pseudo_per_arm)\n",
    "        if valid.any():\n",
    "            best_mean = np.nanmin(mean_pseudo_per_arm[valid])\n",
    "            cum_pseudo = np.cumsum(pseudo_costs)\n",
    "            approx_pseudoregret = cum_pseudo - best_mean * np.arange(1, T + 1)\n",
    "        else:\n",
    "            approx_pseudoregret = np.full(T, np.nan)\n",
    "\n",
    "        # Pseudo-regret vs last chosen arm (as benchmark)\n",
    "        if T > 0:\n",
    "            last_arm_final = int(chosen_arms[T - 1])\n",
    "        else:\n",
    "            last_arm_final = None\n",
    "        if last_arm_final is not None and self.tau[last_arm_final] > 0 and np.isfinite(mean_pseudo_per_arm[last_arm_final]):\n",
    "            mu_last = float(mean_pseudo_per_arm[last_arm_final])\n",
    "            last_arm_pseudoregret = np.cumsum(pseudo_costs) - mu_last * np.arange(1, T + 1)\n",
    "            last_arm_mean = mu_last\n",
    "        else:\n",
    "            last_arm_pseudoregret = np.full(T, np.nan)\n",
    "            last_arm_mean = np.nan\n",
    "\n",
    "        history = {\n",
    "            \"chosen_arms\": chosen_arms,\n",
    "            \"total_cost\": total_costs,\n",
    "            \"modified_cost\": modified_costs,\n",
    "            \"pseudo_cost\": pseudo_costs,\n",
    "            \"avg_modified_cost\": avg_modified_cost,\n",
    "            \"mean_pseudo_cost_per_arm\": mean_pseudo_per_arm,\n",
    "            \"base_stocks\": self.B,\n",
    "            \"approx_pseudoregret\": approx_pseudoregret,\n",
    "            \"last_arm\": last_arm_final if T > 0 else None,\n",
    "            \"last_arm_mean_pseudo_cost\": last_arm_mean,\n",
    "            \"last_arm_pseudoregret\": last_arm_pseudoregret,\n",
    "        }\n",
    "        return history\n",
    "\n",
    "\n",
    "\n",
    "def recommended_grid_m(\n",
    "    T: int,\n",
    "    n: int,\n",
    "    cost_reposition: float = 1.0,\n",
    "    cost_lost: float = 5.0,\n",
    "    safety_factor: float = 1.0,\n",
    "    max_arms: int = 5000,\n",
    ") -> int:\n",
    "    \"\"\"\n",
    "    Recommend a grid resolution m for simplex_grid(n, m) that roughly\n",
    "    matches the theoretical scaling δ(T) ~ (log T / T)^{1/(n+1)}.\n",
    "\n",
    "    Theory sketch:\n",
    "        - Discretization radius δ ≍ (log T / T)^{1/(n+1)}\n",
    "        - Our grid step is 1/m ⇒ δ ≍ 1/m ⇒ m ≍ (T / log T)^{1/(n+1)}.\n",
    "\n",
    "    We also cap the number of arms K = C(m + n - 1, n - 1) by 'max_arms'\n",
    "    to keep the numerical illustration fast and readable.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    T : int\n",
    "        Time horizon.\n",
    "    n : int\n",
    "        Number of locations (dimension of the simplex).\n",
    "    cost_reposition : float\n",
    "        Reposition cost parameter c; used to estimate Lipschitz constant.\n",
    "    cost_lost : float\n",
    "        Lost-sales cost parameter l; used to estimate Lipschitz constant.\n",
    "    safety_factor : float\n",
    "        Multiplicative factor on δ; >1 means coarser grid (smaller m),\n",
    "        <1 means finer grid (larger m).\n",
    "    max_arms : int\n",
    "        Maximum allowed number of arms K = comb(m + n - 1, n - 1).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    m : int\n",
    "        Suggested grid_m for simplex_grid(n, m).\n",
    "    \"\"\"\n",
    "    if T <= 1:\n",
    "        return 1\n",
    "\n",
    "    # Lipschitz constant η ≲ l + 6c (from Lemma in the paper),\n",
    "    # used only to normalize; we largely care about the T, n dependence.\n",
    "    eta = cost_lost + 6.0 * cost_reposition\n",
    "\n",
    "    # Theoretical δ(T) ~ (log T / T)^{1/(n+1)} up to constants;\n",
    "    # we allow a safety_factor to coarsen/fine-tune in practice.\n",
    "    delta_raw = (np.log(T) / T) ** (1.0 / (n + 1))\n",
    "\n",
    "    # Incorporate η and safety_factor as mild rescaling; small δ => larger m.\n",
    "    # Since η only multiplies the discretization term, we keep this simple.\n",
    "    delta = safety_factor * delta_raw\n",
    "\n",
    "    # Translate δ ≈ 1/m  ⇒  m ≈ 1/δ\n",
    "    m = int(np.ceil(1.0 / delta))\n",
    "    m = max(1, m)\n",
    "\n",
    "    # Cap m so that number of arms K does not explode in small experiments.\n",
    "    # K = (m + n - 1 choose n - 1).\n",
    "    while m > 1 and comb(m + n - 1, n - 1) > max_arms:\n",
    "        m -= 1\n",
    "\n",
    "    return m*100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4f6b37f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def simulate_no_reposition(\n",
    "    env: NetworkInventoryEnv,\n",
    "    horizon: int,\n",
    ") -> Dict[str, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Simulate the 'no repositioning' policy:\n",
    "        y_t = x_t  for all t,\n",
    "    i.e., never move inventory proactively.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    env : NetworkInventoryEnv\n",
    "        Environment instance (will be mutated).\n",
    "    horizon : int\n",
    "        Number of periods to simulate.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    history : dict\n",
    "        Same structure as the LipBR history for easy comparison:\n",
    "        - \"total_cost\"\n",
    "        - \"modified_cost\"\n",
    "        - \"avg_modified_cost\"\n",
    "    \"\"\"\n",
    "    n = env.n\n",
    "    T = horizon\n",
    "\n",
    "    total_costs = np.empty(T, dtype=float)\n",
    "    modified_costs = np.empty(T, dtype=float)\n",
    "    avg_modified_cost = np.empty(T, dtype=float)\n",
    "\n",
    "    # Reset environment to a fresh initial state (optional: pass x0).\n",
    "    x = env.reset()\n",
    "    cum_mod = 0.0\n",
    "\n",
    "    for t in range(T):\n",
    "        # No repositioning: target equals current inventory.\n",
    "        y = x.copy()\n",
    "        y_sum = y.sum()\n",
    "        if not np.isclose(y_sum, 1.0):\n",
    "            y = y / y_sum  # ensure on simplex\n",
    "\n",
    "        x_next, total_cost, mod_cost, repo_cost, info = env.step(y)\n",
    "\n",
    "        total_costs[t] = total_cost\n",
    "        modified_costs[t] = mod_cost\n",
    "\n",
    "        cum_mod += mod_cost\n",
    "        avg_modified_cost[t] = cum_mod / (t + 1)\n",
    "\n",
    "        x = x_next\n",
    "\n",
    "    history = {\n",
    "        \"total_cost\": total_costs,\n",
    "        \"modified_cost\": modified_costs,\n",
    "        \"avg_modified_cost\": avg_modified_cost,\n",
    "    }\n",
    "    return history\n",
    "\n",
    "import numpy as np\n",
    "from typing import Dict\n",
    "\n",
    "# --------------------------------------------------------------------\n",
    "# Uniform repositioning baseline simulation\n",
    "# --------------------------------------------------------------------\n",
    "def simulate_uniform_reposition(\n",
    "    env: NetworkInventoryEnv,\n",
    "    horizon: int,\n",
    ") -> Dict[str, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Simulate the 'uniform repositioning' baseline:\n",
    "        y_t = (1/n, ..., 1/n) for all t.\n",
    "\n",
    "    This corresponds to a fixed base-stock policy at the center of the simplex.\n",
    "    At each period, the platform rebalances inventory to the uniform vector,\n",
    "    regardless of the current state x_t.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    env : NetworkInventoryEnv\n",
    "        Environment instance (will be mutated).\n",
    "    horizon : int\n",
    "        Number of periods to simulate.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    history : dict\n",
    "        Dictionary with:\n",
    "        - \"total_cost\": per-period total costs C_t\n",
    "        - \"modified_cost\": per-period modified costs \\\\tilde C_t\n",
    "        - \"avg_modified_cost\": running average of \\\\tilde C_t\n",
    "    \"\"\"\n",
    "    n = env.n\n",
    "    T = horizon\n",
    "\n",
    "    # Fixed uniform base-stock vector\n",
    "    y_uniform = np.ones(n, dtype=float) / n\n",
    "\n",
    "    total_costs = np.empty(T, dtype=float)\n",
    "    modified_costs = np.empty(T, dtype=float)\n",
    "    avg_modified_cost = np.empty(T, dtype=float)\n",
    "\n",
    "    # Reset environment to a fresh initial state (optional: pass x0 if desired)\n",
    "    x = env.reset()\n",
    "    cum_mod = 0.0\n",
    "\n",
    "    for t in range(T):\n",
    "        # Use the same base-stock target every period\n",
    "        x_next, total_cost, mod_cost, repo_cost, info = env.step(y_uniform)\n",
    "\n",
    "        total_costs[t] = total_cost\n",
    "        modified_costs[t] = mod_cost\n",
    "\n",
    "        cum_mod += mod_cost\n",
    "        avg_modified_cost[t] = cum_mod / (t + 1)\n",
    "\n",
    "        x = x_next\n",
    "\n",
    "    history = {\n",
    "        \"total_cost\": total_costs,\n",
    "        \"modified_cost\": modified_costs,\n",
    "        \"avg_modified_cost\": avg_modified_cost,\n",
    "    }\n",
    "    return history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3adf3893",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "def save_history(history: Dict[str, np.ndarray], label: str, outdir: str = \"numerical_results\", extra_meta: Dict[str, str] | None = None, write_metadata_md: bool = False, metadata_md_params: Dict[str, str] | None = None) -> str:\n",
    "    \"\"\"\n",
    "    Save a history dict into a timestamped subfolder for convenient plotting.\n",
    "\n",
    "    Folder structure:\n",
    "      numerical_results/<timestamp>/\n",
    "        - <policy>.csv (policy-specific filename from label)\n",
    "        - params.md (optional, once per run)\n",
    "\n",
    "    Per-period arrays go into the CSV. Non-period arrays are skipped.\n",
    "    \"\"\"\n",
    "    now = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    subdir = os.path.join(outdir, now)\n",
    "    os.makedirs(subdir, exist_ok=True)\n",
    "\n",
    "    # Determine horizon T from 1D arrays\n",
    "    horizon = None\n",
    "    for v in history.values():\n",
    "        arr = np.asarray(v)\n",
    "        if arr.ndim == 1:\n",
    "            horizon = len(arr) if horizon is None else min(horizon, len(arr))\n",
    "    if horizon is None:\n",
    "        horizon = 0\n",
    "\n",
    "    # Build per-period dataframe\n",
    "    df_period = pd.DataFrame(index=range(horizon))\n",
    "    for k, v in history.items():\n",
    "        arr = np.asarray(v)\n",
    "        if arr.ndim == 1 and len(arr) >= horizon:\n",
    "            df_period[k] = arr[:horizon]\n",
    "        elif arr.ndim == 2 and arr.shape[0] >= horizon:\n",
    "            for j in range(arr.shape[1]):\n",
    "                df_period[f\"{k}_{j}\"] = arr[:horizon, j]\n",
    "        # Non-period arrays are ignored for CSV\n",
    "\n",
    "    # Metadata columns embedded in CSV for filtering/grouping\n",
    "    df_period[\"run_timestamp\"] = now\n",
    "    df_period[\"run_label\"] = label\n",
    "    if extra_meta:\n",
    "        for mk, mv in extra_meta.items():\n",
    "            df_period[str(mk)] = str(mv)\n",
    "\n",
    "    # Policy-specific filename: sanitize label\n",
    "    slug = \"\".join(ch.lower() if ch.isalnum() else \"_\" for ch in label).strip(\"_\") or \"history\"\n",
    "    fname = f\"{slug}.csv\"\n",
    "    period_path = os.path.join(subdir, fname)\n",
    "    df_period.to_csv(period_path, index=False)\n",
    "\n",
    "    # Optionally write a single markdown file with parameters (once per run)\n",
    "    if write_metadata_md:\n",
    "        md_path = os.path.join(subdir, \"params.md\")\n",
    "        lines = [\"# Experiment Parameters\\n\\n\"]\n",
    "        if metadata_md_params:\n",
    "            # Make a simple list of key-value pairs\n",
    "            for k, v in metadata_md_params.items():\n",
    "                lines.append(f\"- **{k}**: {v}\\n\")\n",
    "        # Also include timestamp and label\n",
    "        lines.append(f\"\\n- **timestamp**: {now}\\n\")\n",
    "        lines.append(f\"- **labels saved**: {label}\\n\")\n",
    "        with open(md_path, \"a\", encoding=\"utf-8\") as f:\n",
    "            f.writelines(lines)\n",
    "\n",
    "    return os.path.abspath(period_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c681f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def multi_horizon_policy_table_markdown(\n",
    "    histories_by_policy: Dict[str, Dict[int, Dict[str, np.ndarray]]],\n",
    "    decimals: int = 3,\n",
    "    title: str | None = \"Average total cost across horizons\",\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Build a Markdown table where each row is a policy and each column is a\n",
    "    time horizon T, with entries equal to the average total cost over that\n",
    "    horizon for the policy.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    histories_by_policy : dict\n",
    "        Mapping from policy_name -> { T -> history_dict }.\n",
    "        Each history_dict should contain key \"total_cost\": shape (T,).\n",
    "        If a policy lacks a particular T, the cell is left blank.\n",
    "    decimals : int\n",
    "        Number of decimals to display.\n",
    "    title : str | None\n",
    "        Optional title displayed above the table. Set None to omit.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    table_str : str\n",
    "        Markdown-formatted table (with optional title line),\n",
    "        rows = policies, columns = distinct horizons.\n",
    "    \"\"\"\n",
    "    if not histories_by_policy:\n",
    "        return \"No histories provided.\"\n",
    "\n",
    "    # Collect the set of all horizons appearing across policies.\n",
    "    all_Ts = set()\n",
    "    for policy, byT in histories_by_policy.items():\n",
    "        for T in byT.keys():\n",
    "            all_Ts.add(int(T))\n",
    "    sorted_Ts = sorted(all_Ts)\n",
    "\n",
    "    # Build header row.\n",
    "    header = \"| Policy | \" + \" | \".join(f\"T={T}\" for T in sorted_Ts) + \" |\\n\"\n",
    "    align = \"|:-------|\" + \"|\".join([\":----------:\" for _ in sorted_Ts]) + \"|\\n\"\n",
    "\n",
    "    # Build each policy row.\n",
    "    rows = []\n",
    "    for policy, byT in histories_by_policy.items():\n",
    "        cells = []\n",
    "        for T in sorted_Ts:\n",
    "            hist = byT.get(T)\n",
    "            if hist is None or \"total_cost\" not in hist:\n",
    "                cells.append(\"\")\n",
    "            else:\n",
    "                arr = np.asarray(hist[\"total_cost\"])[:T]\n",
    "                val = arr.mean() if arr.size > 0 else float(\"nan\")\n",
    "                cells.append(f\"{val:.{decimals}f}\")\n",
    "        row = \"| \" + policy + \" | \" + \" | \".join(cells) + \" |\"\n",
    "        rows.append(row)\n",
    "\n",
    "    # Optional title line\n",
    "    prefix = f\"**{title}**\\n\\n\" if title else \"\"\n",
    "    return prefix + header + align + \"\\n\".join(rows)\n",
    "\n",
    "\n",
    "def lipbr_last_arm_regret_table_markdown(\n",
    "    histories_by_policy: Dict[str, Dict[int, Dict[str, np.ndarray]]],\n",
    "    decimals: int = 1,\n",
    "    title: str | None = \"LipBR pseudo-regret vs last arm (final cumulative)\",\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Build a one-row Markdown table reporting, for each horizon T, the final\n",
    "    cumulative pseudo-regret of LipBR relative to its last chosen arm.\n",
    "\n",
    "    Expects LipBR histories to include keys:\n",
    "        - \"last_arm_pseudoregret\" (shape (T,))\n",
    "    \"\"\"\n",
    "    if \"LipBR\" not in histories_by_policy or not histories_by_policy[\"LipBR\"]:\n",
    "        return \"No LipBR histories provided.\"\n",
    "\n",
    "    sorted_Ts = sorted(int(T) for T in histories_by_policy[\"LipBR\"].keys())\n",
    "    header = \"| Metric | \" + \" | \".join(f\"T={T}\" for T in sorted_Ts) + \" |\\n\"\n",
    "    align = \"|:-------|\" + \"|\".join([\":----------:\" for _ in sorted_Ts]) + \"|\\n\"\n",
    "\n",
    "    cells = []\n",
    "    for T in sorted_Ts:\n",
    "        hist = histories_by_policy[\"LipBR\"].get(T)\n",
    "        if hist is None or \"last_arm_pseudoregret\" not in hist:\n",
    "            cells.append(\"\")\n",
    "        else:\n",
    "            arr = np.asarray(hist[\"last_arm_pseudoregret\"])[:T]\n",
    "            val = arr[-1] if arr.size > 0 else float(\"nan\")\n",
    "            cells.append(f\"{val:.{decimals}f}\")\n",
    "\n",
    "    row = \"| Final cum. pseudo-regret | \" + \" | \".join(cells) + \" |\"\n",
    "    prefix = f\"**{title}**\\n\\n\" if title else \"\"\n",
    "    return prefix + header + align + row\n",
    "\n",
    "\n",
    "def avg_regret_vs_lipbr_last_arm_table_markdown(\n",
    "    histories_by_policy: Dict[str, Dict[int, Dict[str, np.ndarray]]],\n",
    "    decimals: int = 3,\n",
    "    title: str | None = \"Average pseudo-regret vs LipBR last arm\",\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    For each horizon T, compute average pseudo-regret (1/T sum_t (pseudo_t - mu_last))\n",
    "    for all policies using LipBR's last-arm empirical mean pseudo cost mu_last(T)\n",
    "    as the benchmark.\n",
    "\n",
    "    - For LipBR, use history[\"pseudo_cost\"].\n",
    "    - For baselines (NoRepo, Uniform), use history[\"modified_cost\"] as pseudo costs.\n",
    "    \"\"\"\n",
    "    if \"LipBR\" not in histories_by_policy or not histories_by_policy[\"LipBR\"]:\n",
    "        return \"No LipBR histories provided.\"\n",
    "\n",
    "    # Collect horizons present in LipBR (benchmark availability).\n",
    "    Ts = sorted(int(T) for T in histories_by_policy[\"LipBR\"].keys())\n",
    "\n",
    "    # Header\n",
    "    header = \"| Policy | \" + \" | \".join(f\"T={T}\" for T in Ts) + \" |\\n\"\n",
    "    align = \"|:-------|\" + \"|\".join([\":----------:\" for _ in Ts]) + \"|\\n\"\n",
    "\n",
    "    # Policies to include in rows (intersection with available histories)\n",
    "    policies = [p for p in [\"LipBR\", \"NoRepo\", \"Uniform\"] if p in histories_by_policy]\n",
    "\n",
    "    rows = []\n",
    "    for policy in policies:\n",
    "        cells = []\n",
    "        for T in Ts:\n",
    "            lip_hist = histories_by_policy[\"LipBR\"].get(T)\n",
    "            pol_hist = histories_by_policy[policy].get(T)\n",
    "            if lip_hist is None or pol_hist is None:\n",
    "                cells.append(\"\")\n",
    "                continue\n",
    "            mu_last = lip_hist.get(\"last_arm_mean_pseudo_cost\")\n",
    "            if mu_last is None or not np.isfinite(mu_last):\n",
    "                cells.append(\"\")\n",
    "                continue\n",
    "            # Policy pseudo-cost series\n",
    "            if policy == \"LipBR\":\n",
    "                pc = np.asarray(pol_hist.get(\"pseudo_cost\"))\n",
    "            else:\n",
    "                pc = np.asarray(pol_hist.get(\"modified_cost\"))\n",
    "            if pc is None or pc.size == 0:\n",
    "                cells.append(\"\")\n",
    "                continue\n",
    "            pc = pc[:T]\n",
    "            avg_regret = (pc.sum() - float(mu_last) * len(pc)) / max(len(pc), 1)\n",
    "            cells.append(f\"{avg_regret:.{decimals}f}\")\n",
    "        row = \"| \" + policy + \" | \" + \" | \".join(cells) + \" |\"\n",
    "        rows.append(row)\n",
    "\n",
    "    prefix = f\"**{title}**\\n\\n\" if title else \"\"\n",
    "    return prefix + header + align + \"\\n\".join(rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44a4278",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Running experiments for n=2 =====\n",
      "\n",
      "[ n=2 ] **Average total cost across horizons (averaged over 20 runs)**\n",
      "\n",
      "| Policy | T=1000 | T=2000 | T=3000 |\n",
      "|:-------|:----------:|:----------:|:----------:|\n",
      "| LipBR | 6.322 | 6.363 | 6.409 |\n",
      "| NoRepo | 7.230 | 7.289 | 7.306 |\n",
      "| Uniform | 6.473 | 6.487 | 6.506 |\n",
      "\n",
      "**LipBR pseudo-regret vs last arm (final cumulative, averaged over 20 runs)**\n",
      "\n",
      "| Metric | T=1000 | T=2000 | T=3000 |\n",
      "|:-------|:----------:|:----------:|:----------:|\n",
      "| Final cum. pseudo-regret | 712.2 | -3258.2 | -3169.5 |\n",
      "\n",
      "**Average pseudo-regret vs LipBR last arm (averaged over 20 runs)**\n",
      "\n",
      "| Policy | T=1000 | T=2000 | T=3000 |\n",
      "|:-------|:----------:|:----------:|:----------:|\n",
      "| LipBR | 0.712 | -1.629 | -1.056 |\n",
      "| NoRepo | 1.554 | -0.725 | -0.142 |\n",
      "| Uniform | 0.797 | -1.527 | -0.942 |\n",
      "Saved: /Users/hanshengjiang/Documents/GitHubLocal/LipschitzMDP/numerical_results/20251129-154057/lipbr_n2.csv\n",
      "Saved: /Users/hanshengjiang/Documents/GitHubLocal/LipschitzMDP/numerical_results/20251129-154057/norepo_n2.csv\n",
      "Saved: /Users/hanshengjiang/Documents/GitHubLocal/LipschitzMDP/numerical_results/20251129-154057/uniform_n2.csv\n",
      "\n",
      "===== Running experiments for n=3 =====\n",
      "\n",
      "[ n=3 ] **Average total cost across horizons (averaged over 20 runs)**\n",
      "\n",
      "| Policy | T=1000 | T=2000 | T=3000 |\n",
      "|:-------|:----------:|:----------:|:----------:|\n",
      "| LipBR | 10.533 | 10.593 | 10.537 |\n",
      "| NoRepo | 12.041 | 11.976 | 11.925 |\n",
      "| Uniform | 11.500 | 11.439 | 11.398 |\n",
      "\n",
      "**LipBR pseudo-regret vs last arm (final cumulative, averaged over 20 runs)**\n",
      "\n",
      "| Metric | T=1000 | T=2000 | T=3000 |\n",
      "|:-------|:----------:|:----------:|:----------:|\n",
      "| Final cum. pseudo-regret | 505.1 | 4140.6 | 119.2 |\n",
      "\n",
      "**Average pseudo-regret vs LipBR last arm (averaged over 20 runs)**\n",
      "\n",
      "| Policy | T=1000 | T=2000 | T=3000 |\n",
      "|:-------|:----------:|:----------:|:----------:|\n",
      "| LipBR | 0.505 | 2.070 | 0.040 |\n",
      "| NoRepo | 1.852 | 3.283 | 1.260 |\n",
      "| Uniform | 1.311 | 2.746 | 0.733 |\n",
      "Saved: /Users/hanshengjiang/Documents/GitHubLocal/LipschitzMDP/numerical_results/20251129-154127/lipbr_n3.csv\n",
      "Saved: /Users/hanshengjiang/Documents/GitHubLocal/LipschitzMDP/numerical_results/20251129-154128/norepo_n3.csv\n",
      "Saved: /Users/hanshengjiang/Documents/GitHubLocal/LipschitzMDP/numerical_results/20251129-154128/uniform_n3.csv\n",
      "\n",
      "===== Running experiments for n=4 =====\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Example: closed inventory network with n locations.\n",
    "    # You can now provide a list of n values to sweep over.\n",
    "    n_list = [2, 3, 4]  # e.g., [2, 3, 4]\n",
    "    T_list = [1000, 2000, 3000]  # multiple horizons for the table\n",
    "    num_runs = 20  # repeat experiments and report averages\n",
    "    \n",
    "    # ------------------------------------------------------------------\n",
    "    # Automatic demand mean vector generation\n",
    "    # ------------------------------------------------------------------\n",
    "    def build_demand_mu(n: int, low: float = 0.2, high: float = 0.8) -> np.ndarray:\n",
    "        \"\"\"Create a length-n demand mean vector spanning [low, high].\n",
    "        If n == 1 returns array([low]).\n",
    "        \"\"\"\n",
    "        if n < 1:\n",
    "            raise ValueError(\"n must be >= 1\")\n",
    "        if n == 1:\n",
    "            return np.array([low], dtype=float)\n",
    "        return np.linspace(low, high, n, dtype=float)\n",
    "    \n",
    "    # ------------------------------------------------------------------\n",
    "    # Shared-randomness utilities (common random numbers across policies)\n",
    "    # ------------------------------------------------------------------\n",
    "    def sample_sequences(n: int, T: int, demand_mu: np.ndarray, seed: int):\n",
    "        \"\"\"Pre-sample demand vectors and routing matrices for T periods.\n",
    "        - demand_seq: shape (T, n)\n",
    "        - routing_seq: shape (T, n, n), each row is Dirichlet(1,...,1)\n",
    "        \"\"\"\n",
    "        rng_local = np.random.default_rng(seed)\n",
    "        demand_seq = rng_local.poisson(lam=demand_mu, size=(T, n)).astype(float)\n",
    "        routing_seq = np.empty((T, n, n), dtype=float)\n",
    "        for t in range(T):\n",
    "            routing_seq[t] = rng_local.dirichlet(alpha=np.ones(n), size=n)\n",
    "        return demand_seq, routing_seq\n",
    "    \n",
    "    def make_fixed_samplers(demand_seq: np.ndarray, routing_seq: np.ndarray):\n",
    "        \"\"\"Build deterministic samplers that replay the same sequences per period.\n",
    "        We advance the internal time index once per period (on routing call).\n",
    "        \"\"\"\n",
    "        T, n = demand_seq.shape\n",
    "        idx = {\"t\": 0}\n",
    "        \n",
    "        def demand_sampler_fixed(rng_: np.random.Generator, n_: int) -> np.ndarray:\n",
    "            if n_ != n:\n",
    "                raise ValueError(\"Mismatch: n_ does not equal pre-sampled n.\")\n",
    "            t = idx[\"t\"]\n",
    "            if t >= T:\n",
    "                # Gracefully repeat last value if called beyond horizon\n",
    "                return demand_seq[-1]\n",
    "            return demand_seq[t]\n",
    "        \n",
    "        def routing_sampler_fixed(rng_: np.random.Generator, n_: int) -> np.ndarray:\n",
    "            if n_ != n:\n",
    "                raise ValueError(\"Mismatch: n_ does not equal pre-sampled n.\")\n",
    "            t = idx[\"t\"]\n",
    "            if t >= T:\n",
    "                P = routing_seq[-1]\n",
    "            else:\n",
    "                P = routing_seq[t]\n",
    "            idx[\"t\"] = t + 1\n",
    "            return P\n",
    "        \n",
    "        return demand_sampler_fixed, routing_sampler_fixed\n",
    "    \n",
    "    # Cost parameters (kept consistent across policies)\n",
    "    COST_REPO = 1.0\n",
    "    COST_LOST = 10.0\n",
    "    \n",
    "    # Sweep over the list of n values\n",
    "    for n in n_list:\n",
    "        demand_mu = build_demand_mu(n)  # automatically adapts to n\n",
    "        \n",
    "        print(f\"\\n===== Running experiments for n={n} =====\")\n",
    "        \n",
    "        # Run policies for each T and collect averaged histories across runs.\n",
    "        histories_by_policy_avg: Dict[str, Dict[int, Dict[str, np.ndarray]]] = {\n",
    "            \"LipBR\": {},\n",
    "            \"NoRepo\": {},\n",
    "            \"Uniform\": {},\n",
    "        }\n",
    "        \n",
    "        for T in T_list:\n",
    "            # Use recommended grid resolution with a cap on number of arms\n",
    "            grid_m_T = recommended_grid_m(\n",
    "                T=T,\n",
    "                n=n,\n",
    "                cost_reposition=COST_REPO,\n",
    "                cost_lost=COST_LOST,\n",
    "                safety_factor=1.0,\n",
    "                max_arms=5000,\n",
    "            )\n",
    "            \n",
    "            # Collect per-run histories for averaging\n",
    "            runs_by_policy: Dict[str, list[Dict[str, np.ndarray]]] = {\n",
    "                \"LipBR\": [],\n",
    "                \"NoRepo\": [],\n",
    "                \"Uniform\": [],\n",
    "            }\n",
    "            \n",
    "            base_seed = 20251128  # base seed for reproducibility across days\n",
    "            \n",
    "            for run_idx in range(num_runs):\n",
    "                # Pre-sample identical sequences for all policies in this run\n",
    "                run_seed = base_seed + 1000 * T + run_idx  # depends on T and run\n",
    "                d_seq, P_seq = sample_sequences(n=n, T=T, demand_mu=demand_mu, seed=run_seed)\n",
    "                \n",
    "                # Build fixed samplers; each env gets its own index but same sequences\n",
    "                d_samp_L, P_samp_L = make_fixed_samplers(d_seq, P_seq)\n",
    "                d_samp_N, P_samp_N = make_fixed_samplers(d_seq, P_seq)\n",
    "                d_samp_U, P_samp_U = make_fixed_samplers(d_seq, P_seq)\n",
    "                \n",
    "                # LipBR for horizon T (shared randomness)\n",
    "                cfg = LipBRConfig(horizon=T, grid_m=grid_m_T, H=5.0)\n",
    "                env_lipbr_T = NetworkInventoryEnv(\n",
    "                    n=n,\n",
    "                    demand_sampler=d_samp_L,\n",
    "                    routing_sampler=P_samp_L,\n",
    "                    cost_reposition=COST_REPO,\n",
    "                    cost_lost=COST_LOST,\n",
    "                    rng=np.random.default_rng(123 + run_idx),\n",
    "                )\n",
    "                agent = LipBR(env_lipbr_T, cfg)\n",
    "                runs_by_policy[\"LipBR\"].append(agent.run(verbose=False))\n",
    "                \n",
    "                # No repositioning baseline (shared randomness)\n",
    "                env_norepo_T = NetworkInventoryEnv(\n",
    "                    n=n,\n",
    "                    demand_sampler=d_samp_N,\n",
    "                    routing_sampler=P_samp_N,\n",
    "                    cost_reposition=COST_REPO,\n",
    "                    cost_lost=COST_LOST,\n",
    "                    rng=np.random.default_rng(456 + run_idx),\n",
    "                )\n",
    "                runs_by_policy[\"NoRepo\"].append(\n",
    "                    simulate_no_reposition(env_norepo_T, horizon=T)\n",
    "                )\n",
    "                \n",
    "                # Uniform repositioning baseline (shared randomness)\n",
    "                env_uniform_T = NetworkInventoryEnv(\n",
    "                    n=n,\n",
    "                    demand_sampler=d_samp_U,\n",
    "                    routing_sampler=P_samp_U,\n",
    "                    cost_reposition=COST_REPO,\n",
    "                    cost_lost=COST_LOST,\n",
    "                    rng=np.random.default_rng(789 + run_idx),\n",
    "                )\n",
    "                runs_by_policy[\"Uniform\"].append(\n",
    "                    simulate_uniform_reposition(env_uniform_T, horizon=T)\n",
    "                )\n",
    "            \n",
    "            # --------------------------------------------------------------\n",
    "            # Average metrics across runs for each policy\n",
    "            # --------------------------------------------------------------\n",
    "            def average_histories(hist_list: list[Dict[str, np.ndarray]], T: int) -> Dict[str, np.ndarray]:\n",
    "                if not hist_list:\n",
    "                    return {}\n",
    "                out: Dict[str, np.ndarray] = {}\n",
    "                \n",
    "                # 1D time series keys we care about\n",
    "                keys_1d = [\n",
    "                    \"total_cost\",\n",
    "                    \"modified_cost\",\n",
    "                    \"avg_modified_cost\",\n",
    "                    \"pseudo_cost\",\n",
    "                    \"approx_pseudoregret\",\n",
    "                    \"last_arm_pseudoregret\",\n",
    "                ]\n",
    "                for k in keys_1d:\n",
    "                    series = []\n",
    "                    for h in hist_list:\n",
    "                        if k in h and np.asarray(h[k]).ndim == 1:\n",
    "                            arr = np.asarray(h[k])[:T]\n",
    "                            if arr.size == T:\n",
    "                                series.append(arr)\n",
    "                    if series:\n",
    "                        out[k] = np.mean(np.stack(series, axis=0), axis=0)\n",
    "                \n",
    "                # Scalar keys (averages across runs)\n",
    "                scalar_keys = [\"last_arm_mean_pseudo_cost\"]\n",
    "                for k in scalar_keys:\n",
    "                    vals = []\n",
    "                    for h in hist_list:\n",
    "                        if k in h:\n",
    "                            v = h[k]\n",
    "                            if np.isscalar(v) or (isinstance(v, np.ndarray) and np.asarray(v).ndim == 0):\n",
    "                                try:\n",
    "                                    vals.append(float(v))\n",
    "                                except Exception:\n",
    "                                    pass\n",
    "                    if vals:\n",
    "                        out[k] = float(np.mean(vals))\n",
    "                \n",
    "                return out\n",
    "            \n",
    "            for policy in [\"LipBR\", \"NoRepo\", \"Uniform\"]:\n",
    "                histories_by_policy_avg[policy][T] = average_histories(\n",
    "                    runs_by_policy[policy], T\n",
    "                )\n",
    "        \n",
    "        # Print matrix-style Markdown table: policies x horizons (avg total cost), averaged over runs.\n",
    "        print(\n",
    "            f\"\\n[ n={n} ] \" +\n",
    "            multi_horizon_policy_table_markdown(\n",
    "                histories_by_policy_avg, decimals=3,\n",
    "                title=f\"Average total cost across horizons (averaged over {num_runs} runs)\"\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        # Also print LipBR last-arm pseudo-regret summary across horizons (averaged).\n",
    "        print(\n",
    "            \"\\n\"\n",
    "            + lipbr_last_arm_regret_table_markdown(\n",
    "                histories_by_policy_avg, decimals=1,\n",
    "                title=f\"LipBR pseudo-regret vs last arm (final cumulative, averaged over {num_runs} runs)\"\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        # Print average pseudo-regret vs LipBR last arm for all policies (averaged).\n",
    "        print(\n",
    "            \"\\n\"\n",
    "            + avg_regret_vs_lipbr_last_arm_table_markdown(\n",
    "                histories_by_policy_avg, decimals=3,\n",
    "                title=f\"Average pseudo-regret vs LipBR last arm (averaged over {num_runs} runs)\"\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        # ---------------------------------------------------------------------\n",
    "        # Saving averaged results (largest horizon only)\n",
    "        # ---------------------------------------------------------------------\n",
    "        if 'save_history' in globals():\n",
    "            T_max = max(T_list)\n",
    "            meta_common = {\n",
    "                \"n\": str(n),\n",
    "                \"T\": str(T_max),\n",
    "                \"demand_mu\": \",\".join(map(lambda x: f\"{x:.3f}\", demand_mu)),\n",
    "                \"num_runs\": str(num_runs),\n",
    "                \"shared_randomness\": \"True\",\n",
    "            }\n",
    "            hist_lipbr_Tmax = histories_by_policy_avg[\"LipBR\"].get(T_max, {})\n",
    "            hist_norepo_Tmax = histories_by_policy_avg[\"NoRepo\"].get(T_max, {})\n",
    "            hist_uniform_Tmax = histories_by_policy_avg[\"Uniform\"].get(T_max, {})\n",
    "            \n",
    "            grid_m_Tmax = recommended_grid_m(\n",
    "                T=T_max, n=n, cost_reposition=COST_REPO, cost_lost=COST_LOST, max_arms=5000\n",
    "            )\n",
    "            \n",
    "            lipbr_meta = {\n",
    "                **meta_common,\n",
    "                \"policy\": \"LipBR\",\n",
    "                \"grid_m\": str(grid_m_Tmax),\n",
    "                \"H\": str(5.0),\n",
    "                \"cost_reposition\": str(COST_REPO),\n",
    "                \"cost_lost\": str(COST_LOST),\n",
    "                \"seed\": \"averaged\",\n",
    "            }\n",
    "            norepo_meta = {\n",
    "                **meta_common,\n",
    "                \"policy\": \"NoRepo\",\n",
    "                \"cost_reposition\": str(COST_REPO),\n",
    "                \"cost_lost\": str(COST_LOST),\n",
    "                \"seed\": \"averaged\",\n",
    "            }\n",
    "            uniform_meta = {\n",
    "                **meta_common,\n",
    "                \"policy\": \"Uniform\",\n",
    "                \"cost_reposition\": str(COST_REPO),\n",
    "                \"cost_lost\": str(COST_LOST),\n",
    "                \"seed\": \"averaged\",\n",
    "            }\n",
    "            params_md = {\n",
    "                \"n\": n,\n",
    "                \"T\": T_max,\n",
    "                \"m (grid_m)\": grid_m_Tmax,\n",
    "                \"H\": 5.0,\n",
    "                \"demand_mu\": \",\".join(map(lambda x: f\"{x:.3f}\", demand_mu)),\n",
    "                \"cost_reposition (LipBR)\": COST_REPO,\n",
    "                \"cost_lost (LipBR)\": COST_LOST,\n",
    "                \"cost_reposition (NoRepo)\": COST_REPO,\n",
    "                \"cost_lost (NoRepo)\": COST_LOST,\n",
    "                \"cost_reposition (Uniform)\": COST_REPO,\n",
    "                \"cost_lost (Uniform)\": COST_LOST,\n",
    "                \"num_runs\": num_runs,\n",
    "                \"shared_randomness\": True,\n",
    "            }\n",
    "            lipbr_csv = save_history(hist_lipbr_Tmax, label=f\"LipBR_n{n}\", outdir=\"numerical_results\", extra_meta=lipbr_meta, write_metadata_md=True, metadata_md_params=params_md)\n",
    "            norepo_csv = save_history(hist_norepo_Tmax, label=f\"NoRepo_n{n}\", outdir=\"numerical_results\", extra_meta=norepo_meta, write_metadata_md=False, metadata_md_params=params_md)\n",
    "            uniform_csv = save_history(hist_uniform_Tmax, label=f\"Uniform_n{n}\", outdir=\"numerical_results\", extra_meta=uniform_meta, write_metadata_md=False, metadata_md_params=params_md)\n",
    "            print(f\"Saved: {lipbr_csv}\")\n",
    "            print(f\"Saved: {norepo_csv}\")\n",
    "            print(f\"Saved: {uniform_csv}\")\n",
    "        else:\n",
    "            print(\"Skipping file saves: save_history not loaded in kernel.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "457d4a0c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
